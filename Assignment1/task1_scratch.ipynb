{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGKBoBmyB6m_"
      },
      "source": [
        "Midi file player https://midiplayer.ehubsoft.net/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kteaxf_oyNBs"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwY0-vbiEl2E",
        "outputId": "13791ec1-2cf2-4e20-c540-6f0191391785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1272M  100 1272M    0     0  7569k      0  0:02:52  0:02:52 --:--:--  9.8M\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://cseweb.ucsd.edu/classes/sp25/cse253-a/data/student_files.tar.gz -o student_files.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhIzVc59B5EU"
      },
      "outputs": [],
      "source": [
        "# !rm student_files.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KUD7jSwJB86P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00542c8c-bf08-4e9e-fa38-a4d7eff59167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "student_files/task1_composer_classification/midis/1022.mid\n",
            "student_files/task1_composer_classification/midis/147.mid\n",
            "student_files/task1_composer_classification/midis/275.mid\n",
            "student_files/task1_composer_classification/midis/765.mid\n",
            "student_files/task1_composer_classification/midis/701.mid\n"
          ]
        }
      ],
      "source": [
        "# Make sure to wait until the file fully finishes uploading\n",
        "# !rm -rf student_files\n",
        "!tar -xvzf student_files.tar.gz | tail -n 5  # Make sure there's no error message at the tail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPQbfaHFB-ZM",
        "outputId": "024480c6-a9e9-4cf8-911e-4de98b33f4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Successfully installed miditoolkit-1.0.1 mido-1.3.3\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Successfully installed adagio-0.2.6 aiohttp_cors-0.8.1 alembic-1.15.2 appdirs-1.4.4 autogluon-1.3.0 autogluon.common-1.3.0 autogluon.core-1.3.0 autogluon.features-1.3.0 autogluon.multimodal-1.3.0 autogluon.tabular-1.3.0 autogluon.timeseries-1.3.0 boto3-1.38.20 botocore-1.38.20 catboost-1.2.8 colorama-0.4.6 colorful-0.5.6 colorlog-6.9.0 coreforecast-0.0.15 distlib-0.3.9 evaluate-0.4.3 fs-2.4.16 fugue-0.9.1 gluonts-0.16.1 jmespath-1.0.1 lightning-2.5.1.post0 lightning-utilities-0.14.3 mlforecast-0.13.6 model-index-0.1.11 nlpaug-1.1.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.3.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.0 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.5.1.post0 pytorch-metric-learning-2.8.1 ray-2.44.1 s3transfer-0.12.0 seqeval-1.2.2 statsforecast-2.0.1 tensorboardX-2.6.2.2 timm-1.0.3 torchmetrics-1.7.1 transformers-4.49.0 triad-0.9.8 utilsforecast-0.2.10 virtualenv-20.31.2 window-ops-0.0.15\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa | tail -n 1  # I don't want a super long output\n",
        "!pip install miditoolkit | tail -n 1  # I don't want a super long output\n",
        "!pip install xgboost | tail -n 1  # I don't want a super long output\n",
        "!pip install lightgbm | tail -n 1  # I don't want a super long output\n",
        "!pip install autogluon | tail -n 1  # I don't want a super long output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4BuPE8V4CHR2"
      },
      "outputs": [],
      "source": [
        "# Probably more imports than are really necessary...\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import numpy as np\n",
        "import miditoolkit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
        "import random\n",
        "\n",
        "from mido import MidiFile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from music21 import converter, chord, stream\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knKEqeLNCJda"
      },
      "source": [
        "# Features that didn't work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_suzqRsxCKPG"
      },
      "outputs": [],
      "source": [
        "# def get_chord_features(midi_path):\n",
        "#     try:\n",
        "#         midi_stream = converter.parse(midi_path)\n",
        "#         chords = list(midi_stream.chordify().getElementsByClass(chord.Chord))\n",
        "\n",
        "#         if not chords:\n",
        "#             print(\"no chords\")\n",
        "#             return [], []\n",
        "\n",
        "#         chord_roots = [c.root().midi % 12 for c in chords]  # Pitch class of the root\n",
        "#         chord_qualities = [c.quality for c in chords]\n",
        "#         num_unique_pitches = [len(c.pitches) for c in chords]\n",
        "#         is_major_triad = [1 if c.isMajorTriad() else 0 for c in chords]\n",
        "#         is_minor_triad = [1 if c.isMinorTriad() else 0 for c in chords]\n",
        "#         is_dominant_7th = [1 if c.isDominantSeventh() else 0 for c in chords]\n",
        "\n",
        "#         # Basic chord progression (root note transitions)\n",
        "#         root_note_transitions = []\n",
        "#         for i in range(len(chord_roots) - 1):\n",
        "#             root_note_transitions.append((chord_roots[i], chord_roots[i+1]))\n",
        "\n",
        "#         return [chord_roots, chord_qualities, num_unique_pitches,\n",
        "#                 is_major_triad, is_minor_triad, is_dominant_7th,\n",
        "#                 root_note_transitions]\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing {midi_path} for chords (music21): {e}\")\n",
        "#         return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69zWZFpdCK6L"
      },
      "outputs": [],
      "source": [
        "# def features(path):\n",
        "#     midi_obj = miditoolkit.midi.parser.MidiFile(dataroot1 + '/' + path)\n",
        "\n",
        "#     notes = midi_obj.instruments[0].notes\n",
        "\n",
        "    # Key (2 features) - DIDN'T WORK\n",
        "    # key_info = midi_to_audio_features(dataroot1 + path)\n",
        "    # if key_info:\n",
        "    #     tonic = key_info[0] # Estimated tonic (e.g., 'C', 'C#', 'D', ...)\n",
        "    #     mode = \"major\" if key_info[1] > 0 else \"minor\" # Estimated mode (simplified)\n",
        "    #     # You might want to map tonic to a numerical representation\n",
        "    #     tonic_val = librosa.note_to_midi(tonic + '0') % 12 # Get pitch class (0-11)\n",
        "    #     features.extend([tonic_val, 1 if mode == \"major\" else 0]) # Add as numerical features\n",
        "    # else:\n",
        "    #     features.extend([-1, -1]) # Indicate failure to detect key\n",
        "\n",
        "    # Chords (7 features) - DIDN'T WORK\n",
        "    # features.extend(get_chord_features(dataroot1 + path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RwUOURACNj8"
      },
      "source": [
        "# Getting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VbeS-UtSCMVS"
      },
      "outputs": [],
      "source": [
        "dataroot1 = \"student_files/task1_composer_classification/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "U2X3ARe-COqi"
      },
      "outputs": [],
      "source": [
        "def features(path):\n",
        "    midi_obj = miditoolkit.midi.parser.MidiFile(dataroot1 + '/' + path)\n",
        "\n",
        "    notes = midi_obj.instruments[0].notes\n",
        "\n",
        "    # baseline (2 features)\n",
        "    num_notes = len(notes)\n",
        "    average_pitch = sum([note.pitch for note in notes]) / num_notes\n",
        "    average_duration = sum([note.end - note.start for note in notes]) / num_notes\n",
        "    features = [average_pitch, average_duration]\n",
        "\n",
        "    # notes durations and density (4 features)\n",
        "    durations = [note.end - note.start for note in notes]\n",
        "    # std_dev_duration = np.std(durations)\n",
        "    short_threshold = 0.5 * np.mean(durations)  # or use a fixed value like 0.25\n",
        "    short_notes = [d for d in durations if d < short_threshold]\n",
        "    short_note_ratio = len(short_notes) / len(durations)\n",
        "    mid = MidiFile(dataroot1 + path)\n",
        "    # total_time = mid.length  # in seconds\n",
        "    note_density = num_notes / mid.length\n",
        "    features.extend([short_note_ratio, note_density])\n",
        "\n",
        "    # Volume (3 features)\n",
        "    velocities = np.array([note.velocity for note in notes])\n",
        "    # average_velocity = np.mean(velocities)\n",
        "    # median_velocity = np.median(velocities)\n",
        "    std_dev_velocity = np.std(velocities)\n",
        "    velocity_range = np.max(velocities) - np.min(velocities)\n",
        "    features.extend([std_dev_velocity, velocity_range])\n",
        "\n",
        "    # Get tempo changes (3 features)\n",
        "    tempo_changes = midi_obj.tempo_changes\n",
        "    tempo_values = []\n",
        "    tempo_times = []\n",
        "    average_tempo = 120 # Default tempo if no tempo changes\n",
        "    std_dev_tempo = 0\n",
        "    # num_tempo_changes = 0\n",
        "    if tempo_changes:\n",
        "        # Sort tempo changes by time\n",
        "        tempo_changes.sort(key=lambda x: x.time)\n",
        "        tempo_values = np.array([tempo.tempo for tempo in tempo_changes])\n",
        "        tempo_times = np.array([tempo.time for tempo in tempo_changes])\n",
        "\n",
        "        average_tempo = np.mean(tempo_values)\n",
        "        std_dev_tempo = np.std(tempo_values)\n",
        "        # num_tempo_changes = len(tempo_values)\n",
        "    features.extend([average_tempo, std_dev_tempo])\n",
        "\n",
        "    # Register (5 features)\n",
        "    pitches = np.array([note.pitch for note in notes])\n",
        "    pitch_range = np.max(pitches) - np.min(pitches) if pitches.size > 0 else 0\n",
        "    pitch_max = np.max(pitches)\n",
        "    high_notes = [note for note in notes if note.pitch > 72]  # use 72 (C5, one octave above middle C) as a threshold\n",
        "    high_register_ratio = len(high_notes) / len(notes)\n",
        "    pitches_std_dev = np.std(pitches)\n",
        "    # pitch_mad = np.mean([abs(p - average_pitch) for p in pitches])\n",
        "    features.extend([pitch_range, pitches_std_dev, pitch_max, high_register_ratio])\n",
        "\n",
        "    # Left and right hands (2 features)\n",
        "    # Standard deviation of the highest and lowest 35% of notes (as a proxy for right hand and left hand melodies)\n",
        "    # Idk how accurate this is but let's try, I feel like if std dev is lower then it might be like Mozart and\n",
        "    # if it's higher it might be Chopin or smth\n",
        "    percentile = 35\n",
        "    sorted_pitches = np.sort(pitches)\n",
        "    num_highest_and_lowest_notes = int(np.ceil(num_notes * (percentile / 100)))\n",
        "    highest_pitches = sorted_pitches[-num_highest_and_lowest_notes:]\n",
        "    lowest_pitches = sorted_pitches[:num_highest_and_lowest_notes]\n",
        "    # highest_notes_std_dev = np.std(highest_pitches)\n",
        "    # lowest_notes_std_dev = np.std(lowest_pitches)\n",
        "    highest_notes_range = np.max(highest_pitches) - np.min(highest_pitches)\n",
        "    lowest_notes_range = np.max(lowest_pitches) - np.min(lowest_pitches)\n",
        "    features.extend([highest_notes_range, lowest_notes_range])\n",
        "\n",
        "    # melodic pitch jumps (2 features)\n",
        "    # notes_sorted = sorted(notes, key=lambda n: (n.start, -n.pitch))  # -pitch to get highest first\n",
        "    time_to_highest = {}  # get highest note at each time step\n",
        "    for note in notes:\n",
        "        if note.start not in time_to_highest or note.pitch > time_to_highest[note.start]:\n",
        "            time_to_highest[note.start] = note.pitch\n",
        "    melody_pitches = [time_to_highest[t] for t in sorted(time_to_highest)]\n",
        "    pitch_jumps = [abs(melody_pitches[i+1] - melody_pitches[i]) for i in range(len(melody_pitches) - 1)]\n",
        "    avg_jump = np.mean(pitch_jumps)\n",
        "    # std_jump = np.std(pitch_jumps)\n",
        "    # max_jump = np.max(pitch_jumps)\n",
        "    features.extend([avg_jump])\n",
        "\n",
        "    # Pitch classes\n",
        "    pitch_class_counts = [0] * 12\n",
        "    for note in notes:\n",
        "        pc = note.pitch % 12\n",
        "        pitch_class_counts[pc] += 1\n",
        "    pitch_class_distribution = [count / len(notes) for count in pitch_class_counts]\n",
        "    features.extend(pitch_class_distribution)\n",
        "\n",
        "    # direction changes (1 feature)\n",
        "    diffs = [melody_pitches[i+1] - melody_pitches[i] for i in range(len(melody_pitches) - 1)]\n",
        "    directions = [np.sign(d) for d in diffs]\n",
        "    direction_changes = sum(\n",
        "        1 for i in range(len(directions) - 1) if directions[i] != 0 and directions[i] != directions[i+1]\n",
        "    )\n",
        "    direction_changes_ratio = direction_changes / (len(directions) - 1) if len(directions) > 1 else 0.0\n",
        "    features.extend([direction_changes_ratio])\n",
        "\n",
        "    # Time signature (1 feature)\n",
        "    tsig_count = len(midi_obj.time_signature_changes)\n",
        "    features.extend([tsig_count])\n",
        "\n",
        "    # Autocorrelation\n",
        "    velocities = [note.velocity for note in notes]\n",
        "    v = np.array(velocities)\n",
        "    v_mean = np.mean(v)\n",
        "    numerator = np.sum((v[:-1] - v_mean) * (v[1:] - v_mean))\n",
        "    denominator = np.sum((v - v_mean) ** 2)\n",
        "    vel_autocorr_1 = numerator / denominator if denominator != 0 else 0.0\n",
        "    features.extend([vel_autocorr_1])\n",
        "\n",
        "    # IOI (inter-onset interval)\n",
        "    onsets = sorted([note.start for note in notes])\n",
        "    ioi = np.diff(onsets)  # list of time differences between consecutive onsets\n",
        "    ioi_mean = np.mean(ioi)\n",
        "    ioi_std = np.std(ioi)\n",
        "    features.extend([ioi_mean, ioi_std])\n",
        "\n",
        "    # Unique pitch ratio\n",
        "    unique_pitches = len(set(pitches))\n",
        "    unique_pitch_ratio = unique_pitches / len(pitches)\n",
        "    features.extend([unique_pitch_ratio])\n",
        "\n",
        "    # octave bins\n",
        "    bins = np.arange(0, 128, 12)  # bins edges: 0, 12, 24, ..., 120\n",
        "    octave_hist, _ = np.histogram(pitches, bins=bins)\n",
        "    octave_hist = octave_hist / octave_hist.sum()  # normalize\n",
        "    features.extend(octave_hist.tolist())\n",
        "\n",
        "    # Rhythmic Entropy\n",
        "    if len(ioi) > 1:\n",
        "        # Bin IOIs (rounding helps reduce noise and collapse near-duplicates)\n",
        "        binned_ioi = np.round(ioi, decimals=3)  # Adjust bin size as needed\n",
        "        values, counts = np.unique(binned_ioi, return_counts=True)\n",
        "        probs = counts / counts.sum()\n",
        "        rhythmic_entropy = -np.sum(probs * np.log2(probs))\n",
        "    else:\n",
        "        rhythmic_entropy = 0.0  # No rhythm to analyze\n",
        "    features.extend([rhythmic_entropy])\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "U43rCr3gCPxX"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "train_path = dataroot1 + \"/train.json\"\n",
        "\n",
        "with open(train_path, 'r') as f:\n",
        "    train_json = eval(f.read())\n",
        "\n",
        "files_train_all = [k for k in train_json]\n",
        "X_train_all = [features(k) for k in train_json]\n",
        "y_train_all = [train_json[k] for k in train_json]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2obBTpKHybwZ"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val, files_train, files_val = train_test_split(\n",
        "        X_train_all, y_train_all, files_train_all, test_size=0.2, shuffle=True, random_state=42\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1JYdWqdCRBR",
        "outputId": "154947ec-56bf-4245-930e-b6d100e61ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "midis/5.mid\n",
            "[66.50220264317181, 344.8898678414097, 0.7577092511013216, 9.993379343078677, np.float64(20.247227039731246), np.int64(95), np.float64(167.99993280002687), np.float64(0.0), np.int64(56), np.float64(11.398034628226418), np.int64(91), 0.2643171806167401, np.int64(20), np.int64(29), np.float64(5.829545454545454), 0.07048458149779736, 0.02643171806167401, 0.05286343612334802, 0.09691629955947137, 0.048458149779735685, 0.05286343612334802, 0.07048458149779736, 0.2775330396475771, 0.05726872246696035, 0.030837004405286344, 0.013215859030837005, 0.2026431718061674, 0.6742857142857143, 1, np.float64(0.953737582136841), np.float64(134.44247787610618), np.float64(211.74159564991805), 0.19383259911894274, 0.0, 0.0, 0.004405286343612335, 0.08370044052863436, 0.15859030837004406, 0.45374449339207046, 0.24669603524229075, 0.05286343612334802, 0.0, 0.0, np.float64(2.3246125989162727)]\n",
            "Beethoven\n"
          ]
        }
      ],
      "source": [
        "print(files_train_all[5])\n",
        "print(X_train_all[5])\n",
        "print(y_train_all[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak7kEwdmCSWQ",
        "outputId": "ffc19163-1607-4eeb-9889-7e8fe6dc0437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "midis/872.mid\n",
            "[62.39460370994941, 139.858347386172, 0.0893760539629005, 18.60452955978962, np.float64(30.243173816414657), np.int64(94), np.float64(120.0), np.float64(0.0), np.int64(73), np.float64(15.062750294289366), np.int64(102), 0.2411467116357504, np.int64(36), np.int64(27), np.float64(13.12797619047619), 0.09949409780775717, 0.09274873524451939, 0.05902192242833052, 0.0893760539629005, 0.045531197301854974, 0.1045531197301855, 0.1551433389544688, 0.01517706576728499, 0.09612141652613827, 0.1433389544688027, 0.045531197301854974, 0.05396290050590219, 0.5850746268656717, 1, np.float64(0.9860748786709461), np.float64(51.55236486486486), np.float64(50.01365314755733), 0.11804384485666104, 0.0, 0.0, 0.03372681281618887, 0.11298482293423272, 0.3102866779089376, 0.2866779089376054, 0.1315345699831366, 0.11298482293423272, 0.011804384485666104, 0.0, np.float64(1.596662401863128)]\n",
            "Liszt\n"
          ]
        }
      ],
      "source": [
        "print(files_train[5])\n",
        "print(X_train[5])\n",
        "print(y_train[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvKH4FhYCTC9",
        "outputId": "39b58e62-4a42-4724-f50f-7b7cf53f2b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "midis/943.mid\n",
            "[56.666666666666664, 266.9375, 0.17083333333333334, 20.787422362225513, np.float64(18.23364516415251), np.int64(65), np.float64(330.00033000033), np.float64(0.0), np.int64(60), np.float64(18.953598309790383), np.int64(89), 0.25416666666666665, np.int64(27), np.int64(18), np.float64(11.151515151515152), 0.08333333333333333, 0.06666666666666667, 0.125, 0.09583333333333334, 0.058333333333333334, 0.12083333333333333, 0.020833333333333332, 0.32083333333333336, 0.05416666666666667, 0.0, 0.025, 0.029166666666666667, 0.7404580152671756, 1, np.float64(0.8955237093785035), np.float64(126.52719665271967), np.float64(128.55543670482078), 0.175, 0.0, 0.0, 0.1625, 0.19583333333333333, 0.25833333333333336, 0.12083333333333333, 0.06666666666666667, 0.19583333333333333, 0.0, 0.0, np.float64(1.4958613224704465)]\n",
            "Beethoven\n"
          ]
        }
      ],
      "source": [
        "print(files_val[5])\n",
        "print(X_val[5])\n",
        "print(y_val[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-ecXljiTCTx1"
      },
      "outputs": [],
      "source": [
        "groundtruth_train_all = {k: train_json[k] for k in train_json}\n",
        "groundtruth_train = {k: train_json[k] for k in files_train}\n",
        "groundtruth_val = {k: train_json[k] for k in files_val}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XApJrb2ACUuz"
      },
      "outputs": [],
      "source": [
        "# Testing data\n",
        "test_path = dataroot1 + \"/test.json\"\n",
        "\n",
        "d = eval(open(test_path, 'r').read())\n",
        "\n",
        "files_test = []\n",
        "X_test = []\n",
        "for k in d:\n",
        "    files_test.append(k)\n",
        "    X_test.append(features(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujLYbXCmCV1V",
        "outputId": "25a60bdc-f3ee-4d46-cabf-69be456fc8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "midis/1215.mid\n",
            "[61.4989247311828, 165.19569892473118, 0.002150537634408602, 16.109723796479532, np.float64(22.173068820590668), np.int64(63), np.float64(132.000132000132), np.float64(0.0), np.int64(57), np.float64(9.592587804095453), np.int64(88), 0.1032258064516129, np.int64(23), np.int64(28), np.float64(5.660869565217391), 0.06236559139784946, 0.025806451612903226, 0.17204301075268819, 0.01935483870967742, 0.10752688172043011, 0.023655913978494623, 0.1032258064516129, 0.17204301075268819, 0.012903225806451613, 0.11827956989247312, 0.015053763440860216, 0.16774193548387098, 0.8995633187772926, 1, np.float64(0.9760917482174188), np.float64(65.17241379310344), np.float64(70.27633582460189), 0.09462365591397849, 0.0, 0.0, 0.002150537634408602, 0.08387096774193549, 0.3225806451612903, 0.47956989247311826, 0.0989247311827957, 0.012903225806451613, 0.0, 0.0, np.float64(1.2255148283907524)]\n"
          ]
        }
      ],
      "source": [
        "print(files_test[5])\n",
        "print(X_test[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm0mLFyxCXaq"
      },
      "source": [
        "# Eval Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wODNVWm1CWt2"
      },
      "outputs": [],
      "source": [
        "def accuracy1(groundtruth: dict, predictions):\n",
        "    correct = 0\n",
        "    for k in groundtruth:\n",
        "        if not (k in predictions):\n",
        "            print(\"Missing \" + str(k) + \" from predictions\")\n",
        "            return 0\n",
        "        if predictions[k] == groundtruth[k]:\n",
        "            correct += 1\n",
        "    print(correct, len(groundtruth), correct / len(groundtruth))\n",
        "    return correct / len(groundtruth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTFZLQG3CZVH"
      },
      "source": [
        "# Model: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823rOTDQCavL"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1Y09xwKwCYla"
      },
      "outputs": [],
      "source": [
        "class logisticRegression():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # def predict(self, path, outpath=None):\n",
        "    def predict(self, files, features, outpath=None):\n",
        "        predictions = {}\n",
        "        for i, x in enumerate(features):\n",
        "            k = files[i]\n",
        "            pred = self.model.predict([x])\n",
        "            predictions[k] = str(pred[0])\n",
        "            # print(k, pred)\n",
        "        if outpath:\n",
        "            with open(outpath, \"w\") as z:\n",
        "                z.write(str(predictions) + '\\n')\n",
        "        return predictions\n",
        "\n",
        "    # def train(self, path):\n",
        "    def train(self, X_train, y_train):\n",
        "        model = LogisticRegression(max_iter=5000, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        self.model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "80H1Br9BCd8H"
      },
      "outputs": [],
      "source": [
        "def runLogisticRegressionWithVal():\n",
        "    model = logisticRegression()\n",
        "    model.train(X_train, y_train)\n",
        "    train_preds = model.predict(files_train, X_train)\n",
        "    val_preds = model.predict(files_val, X_val)\n",
        "    test_preds = model.predict(files_test, X_test, \"predictions1_train.json\")\n",
        "\n",
        "    # train_labels = eval(open(dataroot1 + \"/train.json\").read())\n",
        "    # acc1 = accuracy1(train_labels, train_preds)\n",
        "    acc1_train = accuracy1(groundtruth_train, train_preds)\n",
        "    acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "    print(\"Task 1 training accuracy = \" + str(acc1_train))\n",
        "    print(\"Task 1 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FaGcDxx6CeVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48dd4d7c-881f-4160-9f16-f70704cb4b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'predictions1_train.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "711 968 0.734504132231405\n",
            "158 242 0.6528925619834711\n",
            "Task 1 training accuracy = 0.734504132231405\n",
            "Task 1 validation accuracy = 0.6528925619834711\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1_train.json\n",
        "runLogisticRegressionWithVal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JT4wOlxPCgou"
      },
      "outputs": [],
      "source": [
        "# Train will all training data\n",
        "def runLogisticRegression():\n",
        "    model = logisticRegression()\n",
        "    model.train(X_train_all, y_train_all)\n",
        "    train_preds = model.predict(files_train_all, X_train_all)\n",
        "    test_preds = model.predict(files_test, X_test, \"predictions1.json\")\n",
        "\n",
        "    acc1 = accuracy1(groundtruth_train_all, train_preds)\n",
        "    print(\"Task 1 training accuracy = \" + str(acc1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TNAumtrDCiK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bcebe8-35a9-436f-9fda-10d719e4633c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'predictions1.json': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "886 1210 0.7322314049586777\n",
            "Task 1 training accuracy = 0.7322314049586777\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "runLogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiQ5-56wCflW"
      },
      "source": [
        "# Model: XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7mBc_WuCqdp"
      },
      "source": [
        "https://xgboost.readthedocs.io/en/release_3.0.0/parameter.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uhO2xNTsCqLI"
      },
      "outputs": [],
      "source": [
        "class XGBoost():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self, files, features, outpath=None):\n",
        "        predictions = {}\n",
        "        for i, x in enumerate(features):\n",
        "            k = files[i]\n",
        "            pred = self.model.predict([x])\n",
        "            pred = self.label_encoder.inverse_transform(pred)\n",
        "            predictions[k] = str(pred[0])\n",
        "        if outpath:\n",
        "            with open(outpath, \"w\") as z:\n",
        "                z.write(str(predictions) + '\\n')\n",
        "        return predictions\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        # XGBoost wants outputs in [0 1 2 3 4 5 6 7] instead of\n",
        "        # ['Bach' 'Beethoven' 'Chopin' 'Haydn' 'Liszt' 'Mozart' 'Schubert' 'Schumann']\n",
        "        # So we need to encode string labels to numerical values\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
        "        print(f\"Classes found by LabelEncoder (should be 8): {self.label_encoder.classes_}\")\n",
        "        # initialize and train XGBoost classifier\n",
        "        model = XGBClassifier(n_estimators=100, max_depth=10, learning_rate=0.1, objective='multi:softmax')\n",
        "        model.fit(X_train, y_train_encoded)\n",
        "        self.model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "BBEvGA-_Crkf"
      },
      "outputs": [],
      "source": [
        "def runXGBoost():\n",
        "    bst = XGBoost()\n",
        "    bst.train(X_train, y_train)\n",
        "    train_preds = bst.predict(files_train, X_train)\n",
        "    val_preds = bst.predict(files_val, X_val)\n",
        "    test_preds = bst.predict(files_test, X_test, \"predictions1.json\")\n",
        "\n",
        "    acc1_train = accuracy1(groundtruth_train, train_preds)\n",
        "    acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "    print(\"Task 1 training accuracy = \" + str(acc1_train))\n",
        "    print(\"Task 1 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "trcIU1LWCsgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b303b7-981b-4d50-e65f-b717ce4fb1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found by LabelEncoder (should be 8): ['Bach' 'Beethoven' 'Chopin' 'Haydn' 'Liszt' 'Mozart' 'Schubert'\n",
            " 'Schumann']\n",
            "968 968 1.0\n",
            "199 242 0.8223140495867769\n",
            "Task 1 training accuracy = 1.0\n",
            "Task 1 validation accuracy = 0.8223140495867769\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "runXGBoost()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1APSnt3NCtOf"
      },
      "source": [
        "# Model: GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlAokUgzCuwZ"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4lwqCAiCuh4"
      },
      "outputs": [],
      "source": [
        "class skLearnClassifier():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self, files, features, outpath=None):\n",
        "        predictions = {}\n",
        "        for i, x in enumerate(features):\n",
        "            k = files[i]\n",
        "            pred = self.model.predict([x])\n",
        "            predictions[k] = str(pred[0])\n",
        "        if outpath:\n",
        "            with open(outpath, \"w\") as z:\n",
        "                z.write(str(predictions) + '\\n')\n",
        "        return predictions\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=2)\n",
        "        model.fit(X_train, y_train)\n",
        "        self.model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il-oqbKdCxJC"
      },
      "outputs": [],
      "source": [
        "def runSKLearnClassifier():\n",
        "    gbc = skLearnClassifier()\n",
        "    gbc.train(X_train, y_train)\n",
        "    train_preds = gbc.predict(files_train, X_train)\n",
        "    val_preds = gbc.predict(files_val, X_val)\n",
        "    test_preds = gbc.predict(files_test, X_test, \"predictions1.json\")\n",
        "\n",
        "    acc1_train = accuracy1(groundtruth_train, train_preds)\n",
        "    acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "    print(\"Task 1 training accuracy = \" + str(acc1_train))\n",
        "    print(\"Task 1 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19Ud_idpCx5t"
      },
      "outputs": [],
      "source": [
        "!rm predictions1.json\n",
        "runSKLearnClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZvbaFjuC0XQ"
      },
      "source": [
        "# Model: LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xqCbTodCy0T"
      },
      "source": [
        "https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVW75cYbC1-J"
      },
      "outputs": [],
      "source": [
        "class lightGBM():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self, files, features, outpath=None):\n",
        "        predictions = {}\n",
        "        for i, x in enumerate(features):\n",
        "            k = files[i]\n",
        "            pred = self.model.predict([x])\n",
        "            predictions[k] = str(pred[0])\n",
        "        if outpath:\n",
        "            with open(outpath, \"w\") as z:\n",
        "                z.write(str(predictions) + '\\n')\n",
        "        return predictions\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        model = LGBMClassifier(num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        self.model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYsz92yIC2vq"
      },
      "outputs": [],
      "source": [
        "def runLightGBM():\n",
        "    lgbm = lightGBM()\n",
        "    lgbm.train(X_train, y_train)\n",
        "    train_preds = lgbm.predict(files_train, X_train)\n",
        "    val_preds = lgbm.predict(files_val, X_val)\n",
        "    test_preds = lgbm.predict(files_test, X_test, \"predictions1.json\")\n",
        "\n",
        "    acc1_train = accuracy1(groundtruth_train, train_preds)\n",
        "    acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "    print(\"Task 1 training accuracy = \" + str(acc1_train))\n",
        "    print(\"Task 1 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZidtoqOC4Mj"
      },
      "outputs": [],
      "source": [
        "!rm predictions1.json\n",
        "runLightGBM()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_cqaTgzC7O2"
      },
      "source": [
        "# Model: Autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezb7TwLa8kT4"
      },
      "outputs": [],
      "source": [
        "!rm -rf AutogluonModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tpspkJGC7sR"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "num_cores = multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh4VBrlzyouF"
      },
      "outputs": [],
      "source": [
        "# hyperparameters={'GBM': {}, 'RF': {}}\n",
        "hyperparams = {\n",
        "    'XGB': {},         # XGBoost\n",
        "    'GBM': {},         # LightGBM (AutoGluon's GBM refers to LightGBM)\n",
        "    'CAT': {},         # CatBoost\n",
        "    'RF': {},          # Random Forest\n",
        "    # 'XT': {},          # Extra Trees\n",
        "    'GBC': {}          # sklearn.ensemble.GradientBoostingClassifier\n",
        "}\n",
        "# someone said on discord: i can get higher acc with high_quality than best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JRkUjy4yoxL"
      },
      "outputs": [],
      "source": [
        "class AutoGluon():\n",
        "    def __init__(self):\n",
        "        self.label = 'label'\n",
        "\n",
        "    def predict(self, files, features, outpath=None):\n",
        "        df = pd.DataFrame(features)\n",
        "        preds = self.model.predict(df)\n",
        "        predictions = {}\n",
        "        for i, k in enumerate(files):\n",
        "            predictions[k] = str(preds.iloc[i])\n",
        "        if outpath:\n",
        "            with open(outpath, \"w\") as z:\n",
        "                z.write(str(predictions) + '\\n')\n",
        "        return predictions\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        df_train = pd.DataFrame(X_train)\n",
        "        df_train[self.label] = y_train\n",
        "        # also try best_quality if there's time\n",
        "        self.model = TabularPredictor(label=self.label).fit(\n",
        "            df_train,\n",
        "            presets='high_quality',\n",
        "            num_cpus=num_cores,\n",
        "            ag_args_fit={'num_gpus': 1},\n",
        "            # verbosity=4,\n",
        "            ag_args_ensemble =dict(fold_fitting_strategy='sequential_local'),  # disable Ray\n",
        "            save_bag_folds=True\n",
        "        )  # , num_cpus=num_cores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENtSNMkIyxLw"
      },
      "outputs": [],
      "source": [
        "# def runAutoGluon():\n",
        "#     ag = AutoGluon()\n",
        "#     ag.train(X_train_all, y_train_all)\n",
        "#     train_preds = ag.predict(files_train_all, X_train_all)\n",
        "#     val_preds = ag.predict(files_val, X_val)\n",
        "#     test_preds = ag.predict(files_test, X_test, \"predictions1.json\")\n",
        "\n",
        "#     acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "#     acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "#     print(\"Task 1 training accuracy = \" + str(acc1_train))\n",
        "#     print(\"Task 1 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "258u3X0JyxOU"
      },
      "outputs": [],
      "source": [
        "# !rm predictions3.json\n",
        "# runAutoGluon()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK-YG64dyozy"
      },
      "outputs": [],
      "source": [
        "!rm -rf AutogluonModels/\n",
        "\n",
        "# ag = AutoGluon()\n",
        "# ag.train(X_train_all, y_train_all)\n",
        "\n",
        "# Try with a subset of the training data. Idk why but it gave me higher accuracies when I was using XGBoost etc\n",
        "ag = AutoGluon()\n",
        "ag.train(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "NhuKZRY486GZ",
        "outputId": "bf7102a5-3f86-4079-fd7b-5c171de4bcfd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"ag\",\n  \"rows\": 92,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 92,\n        \"samples\": [\n          \"LightGBM_r130_BAG_L1\",\n          \"XGBoost_r33_BAG_L1_FULL\",\n          \"XGBoost_BAG_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04957502503028882,\n        \"min\": 0.7694214876033058,\n        \"max\": 1.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.9900826446280991,\n          0.9214876033057852,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06409680830221,\n        \"min\": 0.6330578512396694,\n        \"max\": 0.9173553719008265,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.8107438016528926,\n          0.7826446280991736,\n          0.8454545454545455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.8368930145175275,\n        \"min\": 0.006546735763549805,\n        \"max\": 20.85770058631897,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          2.9558403491973877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1800565374557663,\n        \"min\": 0.016804218292236328,\n        \"max\": 3.281658172607422,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          0.14652585983276367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 251.94144459263808,\n        \"min\": 0.00990748405456543,\n        \"max\": 1140.4977588653564,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          7.679976940155029\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_test_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9168649073046138,\n        \"min\": 0.0016477108001708984,\n        \"max\": 9.799958229064941,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          2.9558403491973877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18638599329602254,\n        \"min\": 0.0009679794311523438,\n        \"max\": 0.8876776695251465,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          0.14652585983276367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 69.41987836002174,\n        \"min\": 0.00990748405456543,\n        \"max\": 494.47431468963623,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          55.431801319122314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 1,\n        \"max\": 92,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-374c10ca-f121-4ca9-9c92-e6c4640ca21d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_test</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_test</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_test_marginal</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsDist_BAG_L1_FULL</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.011162</td>\n",
              "      <td>0.016804</td>\n",
              "      <td>0.009907</td>\n",
              "      <td>0.011162</td>\n",
              "      <td>0.016804</td>\n",
              "      <td>0.009907</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNeighborsDist_BAG_L1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.680165</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.014780</td>\n",
              "      <td>0.016804</td>\n",
              "      <td>0.009907</td>\n",
              "      <td>0.014780</td>\n",
              "      <td>0.016804</td>\n",
              "      <td>0.009907</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.027998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.931780</td>\n",
              "      <td>0.027998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.931780</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.114830</td>\n",
              "      <td>0.153317</td>\n",
              "      <td>2.654643</td>\n",
              "      <td>0.114830</td>\n",
              "      <td>0.153317</td>\n",
              "      <td>2.654643</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ExtraTrees_r42_BAG_L1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.805785</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.115427</td>\n",
              "      <td>0.153354</td>\n",
              "      <td>1.937892</td>\n",
              "      <td>0.115427</td>\n",
              "      <td>0.153354</td>\n",
              "      <td>1.937892</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>CatBoost_r137_BAG_L1</td>\n",
              "      <td>0.853719</td>\n",
              "      <td>0.782645</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.031458</td>\n",
              "      <td>0.025176</td>\n",
              "      <td>19.201638</td>\n",
              "      <td>0.031458</td>\n",
              "      <td>0.025176</td>\n",
              "      <td>19.201638</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>CatBoost_r13_BAG_L1_FULL</td>\n",
              "      <td>0.845455</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.009927</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.106662</td>\n",
              "      <td>0.009927</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.106662</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>NeuralNetTorch_r86_BAG_L1_FULL</td>\n",
              "      <td>0.826446</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.028210</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.687499</td>\n",
              "      <td>0.028210</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.687499</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>KNeighborsUnif_BAG_L1_FULL</td>\n",
              "      <td>0.769421</td>\n",
              "      <td>NaN</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.012442</td>\n",
              "      <td>0.101894</td>\n",
              "      <td>0.010540</td>\n",
              "      <td>0.012442</td>\n",
              "      <td>0.101894</td>\n",
              "      <td>0.010540</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>KNeighborsUnif_BAG_L1</td>\n",
              "      <td>0.769421</td>\n",
              "      <td>0.633058</td>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.012492</td>\n",
              "      <td>0.101894</td>\n",
              "      <td>0.010540</td>\n",
              "      <td>0.012492</td>\n",
              "      <td>0.101894</td>\n",
              "      <td>0.010540</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>92 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-374c10ca-f121-4ca9-9c92-e6c4640ca21d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-374c10ca-f121-4ca9-9c92-e6c4640ca21d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-374c10ca-f121-4ca9-9c92-e6c4640ca21d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ffceef34-be3f-4aa8-8090-9ab89d19bdfa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ffceef34-be3f-4aa8-8090-9ab89d19bdfa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ffceef34-be3f-4aa8-8090-9ab89d19bdfa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                             model  score_test  score_val eval_metric  \\\n",
              "0       KNeighborsDist_BAG_L1_FULL    1.000000        NaN    accuracy   \n",
              "1            KNeighborsDist_BAG_L1    1.000000   0.680165    accuracy   \n",
              "2       NeuralNetTorch_BAG_L1_FULL    1.000000        NaN    accuracy   \n",
              "3     RandomForestEntr_BAG_L1_FULL    1.000000        NaN    accuracy   \n",
              "4            ExtraTrees_r42_BAG_L1    1.000000   0.805785    accuracy   \n",
              "..                             ...         ...        ...         ...   \n",
              "87            CatBoost_r137_BAG_L1    0.853719   0.782645    accuracy   \n",
              "88        CatBoost_r13_BAG_L1_FULL    0.845455        NaN    accuracy   \n",
              "89  NeuralNetTorch_r86_BAG_L1_FULL    0.826446        NaN    accuracy   \n",
              "90      KNeighborsUnif_BAG_L1_FULL    0.769421        NaN    accuracy   \n",
              "91           KNeighborsUnif_BAG_L1    0.769421   0.633058    accuracy   \n",
              "\n",
              "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
              "0         0.011162       0.016804   0.009907                 0.011162   \n",
              "1         0.014780       0.016804   0.009907                 0.014780   \n",
              "2         0.027998            NaN   6.931780                 0.027998   \n",
              "3         0.114830       0.153317   2.654643                 0.114830   \n",
              "4         0.115427       0.153354   1.937892                 0.115427   \n",
              "..             ...            ...        ...                      ...   \n",
              "87        0.031458       0.025176  19.201638                 0.031458   \n",
              "88        0.009927            NaN   2.106662                 0.009927   \n",
              "89        0.028210            NaN   0.687499                 0.028210   \n",
              "90        0.012442       0.101894   0.010540                 0.012442   \n",
              "91        0.012492       0.101894   0.010540                 0.012492   \n",
              "\n",
              "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
              "0                 0.016804           0.009907            1       True   \n",
              "1                 0.016804           0.009907            1       True   \n",
              "2                      NaN           6.931780            1       True   \n",
              "3                 0.153317           2.654643            1       True   \n",
              "4                 0.153354           1.937892            1       True   \n",
              "..                     ...                ...          ...        ...   \n",
              "87                0.025176          19.201638            1       True   \n",
              "88                     NaN           2.106662            1       True   \n",
              "89                     NaN           0.687499            1       True   \n",
              "90                0.101894           0.010540            1       True   \n",
              "91                0.101894           0.010540            1       True   \n",
              "\n",
              "    fit_order  \n",
              "0          48  \n",
              "1           2  \n",
              "2          58  \n",
              "3          53  \n",
              "4          22  \n",
              "..        ...  \n",
              "87         23  \n",
              "88         71  \n",
              "89         78  \n",
              "90         47  \n",
              "91          1  \n",
              "\n",
              "[92 rows x 13 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_train = pd.DataFrame(X_train_all)\n",
        "# df_train[ag.label] = y_train_all\n",
        "# ag.model.leaderboard(df_train)\n",
        "\n",
        "df_train = pd.DataFrame(X_train)\n",
        "df_train[ag.label] = y_train\n",
        "ag.model.leaderboard(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaZ6Vcpnyo4e",
        "outputId": "48546d51-96e9-45b6-decb-914800b8a0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1210 1210 1.0\n",
            "242 242 1.0\n",
            "Task 3 training accuracy = 1.0\n",
            "Task 3 validation accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "\n",
        "# train_preds_all = ag.predict(files_train_all, X_train_all)\n",
        "train_preds = ag.predict(files_train, X_train)\n",
        "val_preds = ag.predict(files_val, X_val)\n",
        "test_preds = ag.predict(files_test, X_test, \"predictions1.json\")\n",
        "\n",
        "# acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "acc1_train = accuracy1(groundtruth_train, train_preds)\n",
        "acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "print(\"Task 3 training accuracy = \" + str(acc1_train))\n",
        "print(\"Task 3 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqb2Va5eO4-s"
      },
      "source": [
        "### Try predicting with a few other top models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTFnmAcxO_fF"
      },
      "outputs": [],
      "source": [
        "# https://auto.gluon.ai/0.3.1/api/autogluon.predictor.html\n",
        "# predictor.predict(test_data, model=MODEL_NAME)\n",
        "\n",
        "def predictAG(files, features, model_name, outpath=None):\n",
        "    df = pd.DataFrame(features)\n",
        "    preds = ag.model.predict(df)\n",
        "    predictions = {}\n",
        "    for i, k in enumerate(files):\n",
        "        predictions[k] = str(preds.iloc[i])\n",
        "    if outpath:\n",
        "        with open(outpath, \"w\") as z:\n",
        "            z.write(str(predictions) + '\\n')\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbPAack2O3hw",
        "outputId": "87f1eaa7-1b8e-4835-bc66-1d68ff17a110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1210 1210 1.0\n",
            "242 242 1.0\n",
            "Task 3 training accuracy = 1.0\n",
            "Task 3 validation accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "model_name = 'WeightedEnsemble_L3'\n",
        "\n",
        "train_preds_all = predictAG(files_train_all, X_train_all, model_name)\n",
        "val_preds = predictAG(files_val, X_val, model_name)\n",
        "test_preds = predictAG(files_test, X_test, model_name, \"predictions1.json\")\n",
        "\n",
        "acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "print(\"Task 3 training accuracy = \" + str(acc1_train))\n",
        "print(\"Task 3 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bdMsld3O31x",
        "outputId": "734ca1e9-95ef-4525-a989-60fc0e672f08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1210 1210 1.0\n",
            "242 242 1.0\n",
            "Task 3 training accuracy = 1.0\n",
            "Task 3 validation accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "model_name = 'KNeighborsDist_BAG_L1_FULL'\n",
        "\n",
        "train_preds_all = predictAG(files_train_all, X_train_all, model_name)\n",
        "val_preds = predictAG(files_val, X_val, model_name)\n",
        "test_preds = predictAG(files_test, X_test, model_name, \"predictions1.json\")\n",
        "\n",
        "acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "print(\"Task 3 training accuracy = \" + str(acc1_train))\n",
        "print(\"Task 3 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnYjVlX0O4Hf",
        "outputId": "1d200f07-ad99-4e66-8fb6-06842331e04c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1210 1210 1.0\n",
            "242 242 1.0\n",
            "Task 3 training accuracy = 1.0\n",
            "Task 3 validation accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "model_name = 'KNeighborsDist_BAG_L1'\n",
        "\n",
        "train_preds_all = predictAG(files_train_all, X_train_all, model_name)\n",
        "val_preds = predictAG(files_val, X_val, model_name)\n",
        "test_preds = predictAG(files_test, X_test, model_name, \"predictions1.json\")\n",
        "\n",
        "acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "print(\"Task 3 training accuracy = \" + str(acc1_train))\n",
        "print(\"Task 3 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGuSi1OSO4YK",
        "outputId": "d7afb945-ce27-40e0-fdd6-7c56ee2c773b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1210 1210 1.0\n",
            "242 242 1.0\n",
            "Task 3 training accuracy = 1.0\n",
            "Task 3 validation accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "model_name = 'NeuralNetTorch_BAG_L1_FULL'\n",
        "\n",
        "train_preds_all = predictAG(files_train_all, X_train_all, model_name)\n",
        "val_preds = predictAG(files_val, X_val, model_name)\n",
        "test_preds = predictAG(files_test, X_test, model_name, \"predictions1.json\")\n",
        "\n",
        "acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "print(\"Task 3 training accuracy = \" + str(acc1_train))\n",
        "print(\"Task 3 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr_NRpXVO4su",
        "outputId": "60b46541-a115-450d-9d27-66f51872b22b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1210 1210 1.0\n",
            "242 242 1.0\n",
            "Task 3 training accuracy = 1.0\n",
            "Task 3 validation accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "model_name = 'RandomForestEntr_BAG_L1_FULL'\n",
        "\n",
        "train_preds_all = predictAG(files_train_all, X_train_all, model_name)\n",
        "val_preds = predictAG(files_val, X_val, model_name)\n",
        "test_preds = predictAG(files_test, X_test, model_name, \"predictions1.json\")\n",
        "\n",
        "acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "print(\"Task 3 training accuracy = \" + str(acc1_train))\n",
        "print(\"Task 3 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOWi6ikERXtr",
        "outputId": "239d45ce-4058-430d-bfb8-b4f69805a505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1210 1210 1.0\n",
            "242 242 1.0\n",
            "Task 3 training accuracy = 1.0\n",
            "Task 3 validation accuracy = 1.0\n"
          ]
        }
      ],
      "source": [
        "!rm predictions1.json\n",
        "model_name = 'ExtraTrees_r42_BAG_L1'\n",
        "\n",
        "train_preds_all = predictAG(files_train_all, X_train_all, model_name)\n",
        "val_preds = predictAG(files_val, X_val, model_name)\n",
        "test_preds = predictAG(files_test, X_test, model_name, \"predictions1.json\")\n",
        "\n",
        "acc1_train = accuracy1(groundtruth_train_all, train_preds_all)\n",
        "acc1_val = accuracy1(groundtruth_val, val_preds)\n",
        "print(\"Task 3 training accuracy = \" + str(acc1_train))\n",
        "print(\"Task 3 validation accuracy = \" + str(acc1_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXmt3jtWC9U-"
      },
      "source": [
        "# Model: RF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OK2ocxODBGn"
      },
      "source": [
        "# Model: tabpfn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crzfdsMgDDqc"
      },
      "source": [
        "# Model: SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6CXtXKvDFVL"
      },
      "source": [
        "# Model: CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9kzsgi1DH99"
      },
      "source": [
        "# Model: ExtraTrees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ_ncj2XDCG8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Kteaxf_oyNBs",
        "knKEqeLNCJda",
        "1APSnt3NCtOf",
        "rZvbaFjuC0XQ",
        "Kqb2Va5eO4-s"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}