{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FsVjBGZatid-",
        "Oho-VLuOAPQd",
        "pmwVtzPKAPK4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Midi file player https://midiplayer.ehubsoft.net/"
      ],
      "metadata": {
        "id": "o-3rQKgUANwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "KaScwyP7APVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://cseweb.ucsd.edu/classes/sp25/cse253-a/data/student_files.tar.gz -o student_files.tar.gz"
      ],
      "metadata": {
        "id": "Cl8d8kAlE6w1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d7536d-b109-40f2-9e17-9402f8c8f86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1272M  100 1272M    0     0  26.3M      0  0:00:48  0:00:48 --:--:-- 19.8M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm student_files.tar.gz"
      ],
      "metadata": {
        "id": "5UWBggs8AjuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to wait until the file fully finishes uploading\n",
        "# !rm -rf student_files\n",
        "!tar -xvzf student_files.tar.gz | tail -n 5  # Make sure there's no error message at the tail"
      ],
      "metadata": {
        "id": "_B5YAJN-Ajig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef8a0ba-ba9f-4d6a-bb63-a8fee119cba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "student_files/task1_composer_classification/midis/1022.mid\n",
            "student_files/task1_composer_classification/midis/147.mid\n",
            "student_files/task1_composer_classification/midis/275.mid\n",
            "student_files/task1_composer_classification/midis/765.mid\n",
            "student_files/task1_composer_classification/midis/701.mid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa | tail -n 1  # I don't want a super long output\n",
        "!pip install miditoolkit | tail -n 1\n",
        "!pip install xgboost | tail -n 1\n",
        "!pip install lightgbm | tail -n 1"
      ],
      "metadata": {
        "id": "SlltHkCFA7sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d03bc7-5cef-4b44-f3cd-2bcecb7371a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Successfully installed miditoolkit-1.0.1 mido-1.3.3\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Probably more imports than are really necessary...\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "import numpy as np\n",
        "import miditoolkit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
        "import random\n",
        "\n",
        "from mido import MidiFile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from music21 import converter, chord, stream\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier"
      ],
      "metadata": {
        "id": "D71g0OrXA7pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting data"
      ],
      "metadata": {
        "id": "VgT6FcAkAPSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataroot2 = \"student_files/task2_next_sequence_prediction/\""
      ],
      "metadata": {
        "id": "jeT1iULQAkx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Old Solution"
      ],
      "metadata": {
        "id": "FsVjBGZatid-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def features2(path):\n",
        "#     full_path = dataroot2 + 'midis/' + path\n",
        "#     midi_obj = miditoolkit.midi.parser.MidiFile(full_path)\n",
        "\n",
        "#     notes = midi_obj.instruments[0].notes\n",
        "\n",
        "    # # baseline (2 features)\n",
        "    # num_notes = len(notes)\n",
        "    # average_pitch = sum([note.pitch for note in notes]) / num_notes\n",
        "    # average_duration = sum([note.end - note.start for note in notes]) / num_notes\n",
        "    # features = [average_pitch, average_duration]\n",
        "\n",
        "    # # notes durations and density (1 feature)\n",
        "    # durations = [note.end - note.start for note in notes]\n",
        "    # # std_dev_duration = np.std(durations)\n",
        "    # mid = MidiFile(full_path)\n",
        "    # total_time = mid.length  # in seconds\n",
        "    # note_density = num_notes / total_time\n",
        "    # features.extend([note_density])\n",
        "\n",
        "    # # Volume (3 features)\n",
        "    # velocities = np.array([note.velocity for note in notes])\n",
        "    # # average_velocity = np.mean(velocities)\n",
        "    # median_velocity = np.median(velocities)\n",
        "    # std_dev_velocity = np.std(velocities)\n",
        "    # velocity_range = np.max(velocities) - np.min(velocities)\n",
        "    # features.extend([median_velocity, std_dev_velocity, velocity_range])\n",
        "\n",
        "    # # Speed features (2 features)\n",
        "    # note_onsets = np.array([note.start for note in notes])\n",
        "    # onset_diffs = np.diff(note_onsets) # time difference between consecutive note onsets\n",
        "    # average_onset_diff = np.mean(onset_diffs)\n",
        "    # std_dev_onset_diff = np.std(onset_diffs)\n",
        "    # # q1_onsets = np.percentile(onset_diffs, 25)\n",
        "    # # q3_onsets = np.percentile(onset_diffs, 75)\n",
        "    # # iqr_onsets = q3_onsets - q1_onsets\n",
        "    # features.extend([average_onset_diff, std_dev_onset_diff])\n",
        "\n",
        "    # # Get tempo changes (3 features)\n",
        "    # tempo_changes = midi_obj.tempo_changes\n",
        "    # tempo_values = []\n",
        "    # tempo_times = []\n",
        "    # average_tempo = 120 # Default tempo if no tempo changes\n",
        "    # std_dev_tempo = 0\n",
        "    # # num_tempo_changes = 0\n",
        "    # if tempo_changes:\n",
        "    #     # Sort tempo changes by time\n",
        "    #     tempo_changes.sort(key=lambda x: x.time)\n",
        "    #     tempo_values = np.array([tempo.tempo for tempo in tempo_changes])\n",
        "    #     tempo_times = np.array([tempo.time for tempo in tempo_changes])\n",
        "\n",
        "    #     average_tempo = np.mean(tempo_values)\n",
        "    #     std_dev_tempo = np.std(tempo_values)\n",
        "    #     # num_tempo_changes = len(tempo_values)\n",
        "    # features.extend([average_tempo, std_dev_tempo])\n",
        "\n",
        "    # # Register (4 features)\n",
        "    # pitches = np.array([note.pitch for note in notes])\n",
        "    # all_notes_range = np.max(pitches) - np.min(pitches) if pitches.size > 0 else 0\n",
        "    # pitches_std_dev = np.std(pitches)\n",
        "    # # Standard deviation of the highest and lowest 35% of notes (as a proxy for right hand and left hand melodies)\n",
        "    # # Idk how accurate this is but let's try, I feel like if std dev is lower then it might be like Mozart and\n",
        "    # # if it's higher it might be Chopin or smth\n",
        "    # percentile = 35\n",
        "    # sorted_pitches = np.sort(pitches)\n",
        "    # num_highest_and_lowest_notes = int(np.ceil(num_notes * (percentile / 100)))\n",
        "    # highest_pitches = sorted_pitches[-num_highest_and_lowest_notes:]\n",
        "    # lowest_pitches = sorted_pitches[:num_highest_and_lowest_notes]\n",
        "    # highest_notes_std_dev = np.std(highest_pitches)\n",
        "    # lowest_notes_std_dev = np.std(lowest_pitches)\n",
        "    # features.extend([all_notes_range, highest_notes_std_dev, lowest_notes_std_dev, pitches_std_dev])\n",
        "\n",
        "    # # melodic pitch jumps (1 feature)\n",
        "    # # notes_sorted = sorted(notes, key=lambda n: (n.start, -n.pitch))  # -pitch to get highest first\n",
        "    # time_to_highest = {}  # get highest note at each time step\n",
        "    # for note in notes:\n",
        "    #     if note.start not in time_to_highest or note.pitch > time_to_highest[note.start]:\n",
        "    #         time_to_highest[note.start] = note.pitch\n",
        "    # melody_pitches = [time_to_highest[t] for t in sorted(time_to_highest)]\n",
        "    # pitch_jumps = [abs(melody_pitches[i+1] - melody_pitches[i]) for i in range(len(melody_pitches) - 1)]\n",
        "    # avg_jump = np.mean(pitch_jumps) if len(pitch_jumps) > 0 else 0\n",
        "    # features.extend([avg_jump])\n",
        "\n",
        "    # has_nan = np.isnan(np.array(features)).any()\n",
        "    # if has_nan:\n",
        "    #     print(path, \"has NaN\", features)\n",
        "\n",
        "    # return features"
      ],
      "metadata": {
        "id": "uOrlBtpythun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Current Solution"
      ],
      "metadata": {
        "id": "NIghSsbftiVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from collections import Counter\n",
        "\n",
        "# def extract_chord(notes):\n",
        "#     if not notes:\n",
        "#         return ()\n",
        "\n",
        "#     pitch_classes = [note.pitch % 12 for note in notes]\n",
        "#     pc_counter = Counter(pitch_classes)\n",
        "\n",
        "#     # Select the top 3 most common pitch classes (simple chord proxy)\n",
        "#     top_3 = [pc for pc, _ in pc_counter.most_common(3)]\n",
        "#     return tuple(sorted(top_3))  # e.g., (0, 4, 7) = C major"
      ],
      "metadata": {
        "id": "6vlhWyjGHwS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features2(path):\n",
        "    full_path = dataroot2 + 'midis/' + path\n",
        "    midi_obj = miditoolkit.midi.parser.MidiFile(full_path)\n",
        "\n",
        "    notes = midi_obj.instruments[0].notes\n",
        "\n",
        "    abs_features = []  # features to take the absolute value of between two midi files\n",
        "\n",
        "    # tempo\n",
        "    mean_tempo = 120.0  # default\n",
        "    tempo_std = 0.0  # default\n",
        "    tempos = midi_obj.tempo_changes\n",
        "    if tempos:\n",
        "        tempo_values = [t.tempo for t in tempos]\n",
        "        mean_tempo = np.mean(tempo_values)\n",
        "        tempo_std = np.std(tempo_values)\n",
        "    abs_features.extend([mean_tempo, tempo_std])\n",
        "\n",
        "    # time signature\n",
        "    ts_numerator = 4  # default\n",
        "    ts_denominator = 4\n",
        "    tsigs = midi_obj.time_signature_changes\n",
        "    if tsigs:\n",
        "        ts_numerator = tsigs[0].numerator\n",
        "        ts_denominator = tsigs[0].denominator\n",
        "    abs_features.extend([ts_numerator, ts_denominator])\n",
        "\n",
        "    # intervals\n",
        "    time_to_highest = {}  # get highest note at each time step (melody)\n",
        "    time_to_highest_vel = {}  # not for this feature, but will come in handy later\n",
        "    for note in notes:\n",
        "        if note.start not in time_to_highest or note.pitch > time_to_highest[note.start]:\n",
        "            time_to_highest[note.start] = note.pitch\n",
        "            time_to_highest_vel[note.start] = note.velocity\n",
        "    melody_pitches = [time_to_highest[t] for t in sorted(time_to_highest)]\n",
        "    melody_velocities = [time_to_highest_vel[t] for t in sorted(time_to_highest_vel)]  # not for this feature, but will come in handy later\n",
        "    intervals = [abs(melody_pitches[i+1] - melody_pitches[i]) for i in range(len(melody_pitches) - 1)]\n",
        "    avg_interval = 0  # default\n",
        "    intervals_std = 0\n",
        "    if len(intervals) > 0:\n",
        "      avg_interval = np.mean(intervals)\n",
        "      intervals_std = np.std(intervals)\n",
        "    abs_features.extend([avg_interval, intervals_std])\n",
        "\n",
        "    # ioi\n",
        "    onsets = sorted([note.start for note in notes])\n",
        "    ioi = np.diff(onsets)\n",
        "    ioi_mean = 0  # default\n",
        "    ioi_std = 0\n",
        "    if len(ioi) > 0:\n",
        "      ioi_mean = np.mean(ioi)\n",
        "      ioi_std = np.std(ioi)\n",
        "    abs_features.extend([ioi_mean, ioi_std])\n",
        "\n",
        "    # average duration of left and right hand\n",
        "    sorted_by_pitch = sorted(notes, key=lambda n: n.pitch)\n",
        "    num_notes = len(sorted_by_pitch)\n",
        "    # cutoff = int(np.ceil(num_notes * 0.35))  # use 35% as a proxy for left and right hand notes\n",
        "    # left_notes = sorted_by_pitch[:cutoff]\n",
        "    # right_notes = sorted_by_pitch[-cutoff:]\n",
        "    # left_durations = [note.end - note.start for note in left_notes]\n",
        "    # right_durations = [note.end - note.start for note in right_notes]\n",
        "    # left_avg_duration = np.mean(left_durations) if left_durations else 0\n",
        "    # right_avg_duration = np.mean(right_durations) if right_durations else 0\n",
        "    # abs_features.extend([left_avg_duration, right_avg_duration])\n",
        "\n",
        "    # note density\n",
        "    # mid = MidiFile(full_path)\n",
        "    # total_time = mid.length  # in seconds\n",
        "    # note_density = num_notes / total_time\n",
        "    # abs_features.extend([note_density])\n",
        "\n",
        "    # pitch classes\n",
        "    pitch_class_counts = [0] * 12\n",
        "    for note in notes:\n",
        "        pc = note.pitch % 12\n",
        "        pitch_class_counts[pc] += 1\n",
        "    pitch_class_distribution = [count / len(notes) for count in pitch_class_counts]\n",
        "    abs_features.extend(pitch_class_distribution)\n",
        "\n",
        "    # # ticks per beat\n",
        "    # abs_features.extend([midi_obj.ticks_per_beat])\n",
        "\n",
        "    # first and last pitches\n",
        "    first_pitch = melody_pitches[0]\n",
        "    last_pitch = melody_pitches[-1]\n",
        "\n",
        "    # first and last tempos\n",
        "    tempo_changes = midi_obj.tempo_changes\n",
        "    first_tempo = tempo_changes[0].tempo if midi_obj.tempo_changes else 120.0 # Default if no tempo changes\n",
        "    last_tempo = tempo_changes[-1].tempo if midi_obj.tempo_changes else 120.0\n",
        "\n",
        "    # first and last velocities\n",
        "    first_velocity = 0  # default\n",
        "    last_velocity = 0\n",
        "    if melody_velocities:\n",
        "      first_velocity = melody_velocities[0]\n",
        "      last_velocity = melody_velocities[-1]\n",
        "\n",
        "    # first and last time signatures\n",
        "    first_numerator = last_numerator = 4  # default\n",
        "    first_denominator = last_denominator = 4\n",
        "    if midi_obj.time_signature_changes:\n",
        "      time_sigs = midi_obj.time_signature_changes\n",
        "      time_sigs.sort(key=lambda x: x.time)\n",
        "      first_ts = time_sigs[0]\n",
        "      last_ts = time_sigs[-1]\n",
        "      first_numerator = first_ts.numerator\n",
        "      first_denominator = first_ts.denominator\n",
        "      last_numerator = last_ts.numerator\n",
        "      last_denominator = last_ts.denominator\n",
        "\n",
        "    return (abs_features, first_pitch, last_pitch, first_tempo, last_tempo, first_velocity, last_velocity,\n",
        "            first_numerator, first_denominator, last_numerator, last_denominator)"
      ],
      "metadata": {
        "id": "VOxTDSi-BBw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combineFeatures(features_1, features_2):\n",
        "    # features has format (0 abs_features, 1 first_pitch, 2 last_pitch, 3 first_tempo,\n",
        "    # 4 last_tempo, 5 first_velocity, 6 last_velocity, 7 first_numerator, 8 first_denominator,\n",
        "    # 9 last_numerator, 10 last_denominator)\n",
        "    combined_features = [abs(x - y) for x, y in zip(features_1[0], features_2[0])]\n",
        "\n",
        "    # abs(last_pitch_1 - first_pitch_2)\n",
        "    last_pitch_1 = features_1[2]\n",
        "    first_pitch_2 = features_2[1]\n",
        "    interval = abs(last_pitch_1 - first_pitch_2)\n",
        "    combined_features.append(interval)\n",
        "\n",
        "    # how many standard deviations is this interval off from the mean interval for both midi files?\n",
        "    z_1 = (interval - features_1[0][4]) / features_1[0][5] if features_1[0][5] > 0 else 0\n",
        "    z_2 = (interval - features_2[0][4]) / features_2[0][5] if features_2[0][5] > 0 else 0\n",
        "    combined_features.extend([z_1, z_2])\n",
        "\n",
        "    # abs(end_tempo_1 - start_tempo_2)\n",
        "    end_tempo_1 = features_1[4]\n",
        "    start_tempo_2 = features_2[3]\n",
        "    combined_features.append(abs(start_tempo_2 - end_tempo_1))\n",
        "\n",
        "    # velocity\n",
        "    end_velocity_1 = features_1[6]\n",
        "    start_velocity_2 = features_2[5]\n",
        "    combined_features.append(abs(end_velocity_1 - start_velocity_2))\n",
        "\n",
        "    # time signature\n",
        "    end_numerator_1 = features_1[9]\n",
        "    start_numerator_2 = features_2[7]\n",
        "    combined_features.append(abs(end_numerator_1 - start_numerator_2))\n",
        "    end_denominator_1 = features_1[10]\n",
        "    start_denominator_2 = features_2[8]\n",
        "    combined_features.append(abs(end_denominator_1 - start_denominator_2))\n",
        "\n",
        "    return combined_features"
      ],
      "metadata": {
        "id": "2NDhFuBABFya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to only get feature vectors once since they're costly, so save them in a dictionary\n",
        "features = {}\n",
        "midi_dir = dataroot2 + \"midis/\"\n",
        "for f in os.listdir(midi_dir):\n",
        "    features[\"midis/\" + f] = features2(f)"
      ],
      "metadata": {
        "id": "W4E9gIMyBG6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "train_path = dataroot2 + \"train.json\"\n",
        "\n",
        "with open(train_path, 'r') as f:\n",
        "    train_json = eval(f.read())\n",
        "\n",
        "file_pairs_train_all = [k for k in train_json]\n",
        "X_train_all = [combineFeatures(features[k1], features[k2]) for (k1, k2) in file_pairs_train_all]\n",
        "y_train_all = [train_json[k] for k in train_json]"
      ],
      "metadata": {
        "id": "civlkFt_BRdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val, file_pairs_train, file_pairs_val = train_test_split(\n",
        "        X_train_all, y_train_all, file_pairs_train_all, test_size=0.2, random_state=42, shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "2fOrRAqo4dD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_pairs_train_all[5])\n",
        "print(X_train_all[5])\n",
        "print(y_train_all[5])"
      ],
      "metadata": {
        "id": "FopEtKyJBUcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b096d343-4e3d-43d2-de41-b2e3e8c98320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('midis/277.mid', 'midis/4421.mid')\n",
            "[np.float64(43.99984693347619), np.float64(0.0), 8, 12, np.float64(1.640289449112979), np.float64(3.203235798902703), np.float64(50.20626432391139), np.float64(25.060308506588974), 0.01318407960199005, 0.13706467661691543, 0.0017412935323383085, 0.11007462686567164, 0.12213930348258706, 0.0017412935323383085, 0.13507462686567165, 0.06629353233830845, 0.027363184079602004, 0.05348258706467661, 0.03955223880597014, 0.10348258706467661, 19, np.float64(2.516008896101268), np.float64(6.717672771012024), 43.99984693347619, 16, 8, 12]\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_pairs_train[5])\n",
        "print(X_train[5])\n",
        "print(y_train[5])"
      ],
      "metadata": {
        "id": "OApSvqL9BU8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f9b238-076d-4f9d-b699-658dfd742c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('midis/1804.mid', 'midis/3392.mid')\n",
            "[np.float64(0.0), np.float64(0.0), 0, 0, np.float64(4.16017316017316), np.float64(3.3261466034200797), np.float64(122.52964426877472), np.float64(115.26479133647302), 0.18856837606837606, 0.0, 0.05523504273504274, 0.09487179487179487, 0.044444444444444446, 0.3594017094017094, 0.03482905982905983, 0.33418803418803417, 0.044444444444444446, 0.08226495726495725, 0.060042735042735045, 0.08888888888888889, 7, np.float64(0.23652495839563298), np.float64(2.3770798118187906), 0.0, 0, 0, 0]\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_pairs_val[5])\n",
        "print(X_val[5])\n",
        "print(y_val[5])"
      ],
      "metadata": {
        "id": "cqmT1qlXBVNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d343263d-ee68-4d20-88fc-4832de8ead87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('midis/118.mid', 'midis/1058.mid')\n",
            "[np.float64(0.0), np.float64(0.0), 0, 0, np.float64(4.933333333333332), np.float64(0.6249702817584453), np.float64(9.230769230769226), np.float64(0.3555563370856589), 0.13363139592647788, 0.07054148037754596, 0.05042225534028813, 0.02533532041728763, 0.0, 0.09860904123199205, 0.03676105315449578, 0.0, 0.021112767014406342, 0.0, 0.1174863387978142, 0.002483854942871337, 7, np.float64(-0.5777858063494004), np.float64(-0.9449825521403139), 0.0, 1, 0, 0]\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groundtruth_train_all = {k: train_json[k] for k in train_json}\n",
        "groundtruth_train = {k: train_json[k] for k in file_pairs_train}\n",
        "groundtruth_val = {k: train_json[k] for k in file_pairs_val}"
      ],
      "metadata": {
        "id": "aHlrKlAABVWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing data\n",
        "test_path = dataroot2 + \"test.json\"\n",
        "\n",
        "d = eval(open(test_path, 'r').read())\n",
        "\n",
        "file_pairs_test = [k for k in d]\n",
        "X_test = [combineFeatures(features[k1], features[k2]) for (k1, k2) in file_pairs_test]"
      ],
      "metadata": {
        "id": "WFQbbcLoBVmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_pairs_test[5])\n",
        "print(X_test[5])"
      ],
      "metadata": {
        "id": "JlLZNSkSBZ4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134bacf7-b8c3-49b3-975e-33daf48c42aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('midis/5257.mid', 'midis/6086.mid')\n",
            "[np.float64(0.0), np.float64(0.0), 0, 0, np.float64(4.502298850574713), np.float64(2.361707192462271), np.float64(32.76880901614378), np.float64(41.255875409854895), 0.0, 0.02035056446821154, 0.07635175282234107, 0.0008912655971479513, 0.11125965537730245, 0.0707070707070707, 0.023767082590612, 0.0, 0.08348187759952465, 0.044860368389780136, 0.0, 0.015745692216280444, 1, np.float64(-0.5511977325378299), np.float64(-1.0237986040928249), 0.0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval Function"
      ],
      "metadata": {
        "id": "Oho-VLuOAPQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy2(groundtruth, predictions):\n",
        "    correct = 0\n",
        "    for k in groundtruth:\n",
        "        if not (k in predictions):\n",
        "            print(\"Missing \" + str(k) + \" from predictions\")\n",
        "            return 0\n",
        "        if predictions[k] == groundtruth[k]:\n",
        "            correct += 1\n",
        "    return correct / len(groundtruth)"
      ],
      "metadata": {
        "id": "t1G0wk_WAlJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: Logistic Regression"
      ],
      "metadata": {
        "id": "cw64athKAPOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ],
      "metadata": {
        "id": "vrFNaOufBefN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class logisticReg():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        model = LogisticRegression(max_iter=5000, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, file_pairs, features, outpath=None):\n",
        "        predictions = {}\n",
        "        for i, x in enumerate(features):\n",
        "            k = file_pairs[i]\n",
        "            pred = self.model.predict([x])\n",
        "            predictions[k] = bool(pred[0])  # pred is [True] or [False]\n",
        "            # print(k, pred)\n",
        "        if outpath:\n",
        "            with open(outpath, \"w\") as z:\n",
        "                z.write(str(predictions) + '\\n')\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "CRL8-zlTAl2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runLogisticRegression():\n",
        "    model = logisticReg()\n",
        "    model.train(X_train, y_train)\n",
        "    train_preds = model.predict(file_pairs_train, X_train)\n",
        "    val_preds = model.predict(file_pairs_val, X_val)\n",
        "    test_preds = model.predict(file_pairs_test, X_test, \"predictions2.json\")\n",
        "\n",
        "    acc1_train = accuracy2(groundtruth_train, train_preds)\n",
        "    acc1_val = accuracy2(groundtruth_val, val_preds)\n",
        "    print(\"Task 1 training accuracy = \" + str(acc1_train))\n",
        "    print(\"Task 1 validation accuracy = \" + str(acc1_val))"
      ],
      "metadata": {
        "id": "V-1Qo-b7Bhjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm predictions2.json\n",
        "runLogisticRegression()"
      ],
      "metadata": {
        "id": "qn0tmnaLBikE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6416fdb9-ed01-4118-b6a4-707ecfa458bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 training accuracy = 0.9794663876536751\n",
            "Task 1 validation accuracy = 0.9864016736401674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: Decision Trees"
      ],
      "metadata": {
        "id": "pmwVtzPKAPK4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rKC_1SyYAnDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: XGBoost"
      ],
      "metadata": {
        "id": "zi_l36bEAPIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XGBoost():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self, files, features, outpath=None):\n",
        "        predictions = {}\n",
        "        for i, x in enumerate(features):\n",
        "            k = files[i]\n",
        "            pred = self.model.predict([x])\n",
        "            pred = self.label_encoder.inverse_transform(pred)\n",
        "            predictions[k] = bool(pred[0])\n",
        "            # print(k, pred[0])\n",
        "        if outpath:\n",
        "            with open(outpath, \"w\") as z:\n",
        "                z.write(str(predictions) + '\\n')\n",
        "        return predictions\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        # XGBoost wants outputs in [0 1] instead of [True False]\n",
        "        # So we need to encode boolean labels to numerical values\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
        "        print(f\"Classes found by LabelEncoder (should be 2): {self.label_encoder.classes_}\")\n",
        "        model = XGBClassifier(n_estimators=500, max_depth=15, learning_rate=0.1, objective='binary:logistic')\n",
        "        model.fit(X_train, y_train_encoded)\n",
        "        self.model = model"
      ],
      "metadata": {
        "id": "DZXEAdyuAmww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runXGBoost():\n",
        "    model = XGBoost()\n",
        "    model.train(X_train_all, y_train_all)\n",
        "    train_preds = model.predict(file_pairs_train, X_train)\n",
        "    val_preds = model.predict(file_pairs_val, X_val)\n",
        "    test_preds = model.predict(file_pairs_test, X_test, \"predictions2.json\")\n",
        "\n",
        "    acc1_train = accuracy2(groundtruth_train, train_preds)\n",
        "    acc1_val = accuracy2(groundtruth_val, val_preds)\n",
        "    print(\"Task 1 training accuracy = \" + str(acc1_train))\n",
        "    print(\"Task 1 validation accuracy = \" + str(acc1_val))"
      ],
      "metadata": {
        "id": "g5L-9pKL3023"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm predictions2.json\n",
        "runXGBoost()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhjannDO32H2",
        "outputId": "ee42b13f-296b-4cb7-a878-089c78592e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found by LabelEncoder (should be 2): [False  True]\n",
            "Task 1 training accuracy = 1.0\n",
            "Task 1 validation accuracy = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: Autogluon"
      ],
      "metadata": {
        "id": "3yMX9zysAPDS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42YIR7i2Amd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model: MLP"
      ],
      "metadata": {
        "id": "R9l7P7uHAPGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri3Ti-oUACFb"
      },
      "outputs": [],
      "source": []
    }
  ]
}